OpenAI:
  api_key: 'API_KEY'

# Possible model values
# gpt-3.5-turbo, gpt-3.5-turbo-16k, gpt-3.5-turbo-0613, gpt-3.5-turbo-16k-0613
# gpt-4, gpt-4-0613, gpt-4-32k, gpt-4-32k-0613
# Legacy models
# text-davinci-003, text-davinci-002, code-davinci-002
# See this link for available models
# https://platform.openai.com/docs/models/continuous-model-upgrades
  ai_model: gpt-3.5-turbo-0301
# Language in which ChatGPT should respond.
# List of languages available for openAI is available at
# https://platform.openai.com/docs/guides/speech-to-text/supported-languages
  response_lang: English

# These are used for single turn responses only. These will go away at some point of time
  default_prompt_preamble: "You are a casual pal, genuinely interested in the conversation at hand. A poor transcription of conversation is given below."
  default_prompt_epilogue: "Please respond, to the conversation. Confidently give a straightforward response to the speaker, even if you don't understand them. Give your response in square brackets. DO NOT ask to repeat, and DO NOT ask for clarification. Just answer the speaker directly."

# The combination of system_prompt, initial_convo is used to create a multi turn prompt message for LLM.
# system_prompt_1, systen_prompt_2 are here as samples of other possible prompts.
# Only the content of system_prompt parameter will be used
  system_prompt: "You are a casual pal, genuinely interested in the conversation at hand. Please respond, in detail, to the conversation. Confidently give a straightforward response to the speaker, even if you don't understand them. Give your response in square brackets. DO NOT ask to repeat, and DO NOT ask for clarification. Just answer the speaker directly."
#  system_prompt: "You are an expert at Basketball and helping others learn about basketball. Please respond, in detail, to the conversation. Confidently give a straightforward response to the speaker, even if you don't understand them. Give your response in square brackets. DO NOT ask to repeat, and DO NOT ask for clarification. Just answer the speaker directly."
#  system_prompt: "You are an expert at Fantasy Football and helping others learn about Fantasy football. Please respond, in detail, to the conversation. Confidently give a straightforward response to the speaker, even if you don't understand them. Give your response in square brackets. DO NOT ask to repeat, and DO NOT ask for clarification. Just answer the speaker directly."
#  system_prompt: â€œYou are an expert Agile Coach and are interviewing for a position. Respond in detail to the conversation. Confidently give a straightforward response to the speaker, even if you don't understand them. Give your response in square brackets. DO NOT ask to repeat, and DO NOT ask for clarification. Just answer the speaker directly."

# When we anticipate to talk about a specific topic, seed the content with some conversation
# Application expects role "You" to have 1 entry
# If the conversation is generic, replace this text with something like this.
#   role: You
#   content: I am V, I want to have a casual friendly conversation
#   role: assistant
#   content: Hello V, That's awesome! Glad to meet you and I am looking forward to our conversation today
  initial_convo:
    first:
      role: "You"
      # content: "I am V, I want to learn about Fantasy Football"
      # content: "I am V, I want to learn about Basketball"
      # content: "Hey assistant, how are you doing today, I want to talk about Agile coaching today."
      content: Hey assistant, how are you doing today, I am in mood of a casual conversation.
    second:
      role: "assistant"
      # content: "Hello, V. That's awesome! What do you want to know about basketball"
      # content: "Hello, V. That's awesome! What do you want to know about Fantasy Football"
      # content: "Hello, V. You are awesome. I am doing very well and looking forward to discussion about Agile coaching."
      content: Hello, V. You are awesome. I am doing very well and looking forward to some light hearted banter with you.

General:
  log_file: 'Transcribe.log'
  # These two parameters are used together.
  # Save LLM response to file if save_llm_response_to_file is Yes
  save_llm_response_to_file: Yes # Possible values are Yes, No
  llm_response_file: 'response.txt'
# Attempt transcription of the sound file after these number of seconds
  transcript_audio_duration_seconds: 3
# These two parameters are used together.
# Setting clear_transcript_periodically: yes will clear transcript data at a regular interval
# clear_transcript_interval_seconds is applicable when clear_transcript_periodically is set to Yes
  clear_transcript_periodically: No # Possible values are Yes, No
  clear_transcript_interval_seconds: 60
